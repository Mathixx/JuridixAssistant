adam_epsilon: 1.0e-08
data_dir: ''
early_stop_callback: false
eval_batch_size: 4
fp_16: false
gradient_accumulation_steps: 16
learning_rate: 0.0003
max_grad_norm: 1.0
max_seq_length: 512
model_name_or_path: google/mt5-small
n_gpu: 1
num_train_epochs: 4
opt_level: O1
output_dir: /users/eleves-b/2022/mathias.perez/Desktop/JuridixAssistant/data/Juridix/saved_models/ft_mt5
path_to_csv: _dataset1.csv
seed: 42
tokenizer_name_or_path: google/mt5-small
train_batch_size: 8
warmup_steps: 0
weight_decay: 0.0
